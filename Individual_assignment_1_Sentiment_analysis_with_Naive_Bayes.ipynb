{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BharathKanama/Bharathprakash143.github.io/blob/master/Individual_assignment_1_Sentiment_analysis_with_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDVS1X_EleqW"
      },
      "source": [
        "In this individual assignment we will take a look at sentiment analysis task with Naive Bayes classifier.\n",
        "\n",
        "---\n",
        "\n",
        "Assignment consists of 3 parts:\n",
        "\n",
        "\n",
        "*   Data exploration\n",
        "*   Sentiment classification\n",
        "*   Report\n",
        "\n",
        "\n",
        "You can use the following references as a guide for your homework:\n",
        "\n",
        "* https://www.enjoyalgorithms.com/blog/sentiment-analysis-using-naive-bayes\n",
        "* https://www.enjoyalgorithms.com/blog/text-data-pre-processing-techniques-in-ml\n",
        "* https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n",
        "* For precision, recall, f1 refer to https://scikit-learn.org/stable/modules/classes.html?highlight=metrics#module-sklearn.metrics\n",
        "\n",
        "To access dataset:\n",
        "\n",
        "Option 1: upload data to your Google Drive, then mount the drive\n",
        "\n",
        "Option 2: upload directly to colab\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNZ8RoOYkB42",
        "outputId": "1f05f182-e9c2-4557-d01c-4e6dcd9d5721"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS8e-YuVqpqh"
      },
      "source": [
        "First let's import all neccessary for this assignment modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPk7NnKv8dF1",
        "outputId": "37f12b3d-454b-401b-eb21-edc79dc7eeac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scattertext\n",
            "  Downloading scattertext-0.1.7-py3-none-any.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.0.2)\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Collecting gensim>=4.0.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from scattertext) (0.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->scattertext) (5.2.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scattertext) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scattertext) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scattertext) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scattertext) (1.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->scattertext) (0.5.2)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=464044f9c4e3d5483937d69b4a0898707e3356a309829a25256940f0dee27f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "Successfully built flashtext\n",
            "Installing collected packages: mock, gensim, flashtext, scattertext\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed flashtext-2.7 gensim-4.2.0 mock-4.0.3 scattertext-0.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install scattertext"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scattertext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8SFVDfD_Xf7",
        "outputId": "a8cac674-b97a-49f1-e59a-41f1bb215344"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scattertext\n",
            "  Downloading scattertext-0.1.7-py3-none-any.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.7.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from scattertext) (0.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.3.5)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting flashtext\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from scattertext) (1.0.2)\n",
            "Collecting gensim>=4.0.0\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 77.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->scattertext) (5.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scattertext) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->scattertext) (2022.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scattertext) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->scattertext) (1.2.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->scattertext) (0.5.3)\n",
            "Building wheels for collected packages: flashtext\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9309 sha256=49d80523bf7784f705932b93c7cfd37fc1dc7f7c328cf738d679ae59153fc815\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "Successfully built flashtext\n",
            "Installing collected packages: mock, gensim, flashtext, scattertext\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed flashtext-2.7 gensim-4.2.0 mock-4.0.3 scattertext-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QCwiBfhBAP0V"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import scattertext as st\n",
        "import spacy\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import TextBlob\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
        "from sklearn import metrics\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWmi0ElXqxQ4"
      },
      "source": [
        "Now, pick a dataset for the analysis from the following:\n",
        "\n",
        "\n",
        "*   Financial dataset (https://www.kaggle.com/datasets/sbhatti/financial-sentiment-analysis)\n",
        "*   Movie review (https://www.kaggle.com/code/lakshmi25npathi/sentiment-analysis-of-imdb-movie-reviews/data)\n",
        "* Amazon Kindle Book Review (https://www.kaggle.com/datasets/meetnagadia/amazon-kindle-book-review-for-sentiment-analysis) - use 'preprocessed_kindle_review.csv and convert rating into sentiment: 1-2: negative, 3: neutral, 4-5: positive\n",
        "* Steam Reviews (https://www.kaggle.com/datasets/piyushagni5/sentiment-analysis-for-steam-reviews) use train.csv and treat 'user_suggestion' as a Sentiment 1-positive, 0-negative\n",
        "\n",
        "Download it from kaggle.com and upload to this colab: left menu 'Files'-> 'Upload file'\n",
        "\n",
        "**Make sure that your file is fully uploaded before proceeding**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9x_IeO5vcZ9"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "nBBkoUE869rw"
      },
      "outputs": [],
      "source": [
        "# Use pd.read_csv to upload dataset [~ 1 line].\n",
        "# You can use 'usecols' argument to specify which columns to load\n",
        "\n",
        "\n",
        "# Your code here:\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(\"/content/sample_data/california_housing_test.csv\",usecols=[\"longitude\", \"latitude\", \"total_rooms\",\"population\"])\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "bJsFqpfy7gCi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2e883e52-1824-4a22-a421-d7a7d35f7c2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   longitude  latitude  total_rooms  population\n",
              "0    -122.05     37.37       3885.0      1537.0\n",
              "1    -118.30     34.26       1510.0       809.0\n",
              "2    -117.81     33.78       3589.0      1484.0\n",
              "3    -118.36     33.82         67.0        49.0\n",
              "4    -119.67     36.33       1241.0       850.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeb74e1d-aa0b-4f90-9501-8d455966a4f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>population</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>1537.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>809.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>1484.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>67.0</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>850.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeb74e1d-aa0b-4f90-9501-8d455966a4f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aeb74e1d-aa0b-4f90-9501-8d455966a4f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aeb74e1d-aa0b-4f90-9501-8d455966a4f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# You can take a look at first 5 entries with the following\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas.core.arrays.datetimes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_ztu3KY-ycx",
        "outputId": "c5e86898-2327-486e-d257-877befa1cf6d"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pandas.core.arrays.datetimes (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pandas.core.arrays.datetimes\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "DJ6QLqpBkdnT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a054c32-c3f4-41d1-d205-f989b73caf91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      longitude  latitude  total_rooms  population sentiment\n",
            "0       -122.05     37.37       3885.0      1537.0  positive\n",
            "1       -118.30     34.26       1510.0       809.0   neutral\n",
            "2       -117.81     33.78       3589.0      1484.0  positive\n",
            "3       -118.36     33.82         67.0        49.0  negative\n",
            "4       -119.67     36.33       1241.0       850.0   neutral\n",
            "...         ...       ...          ...         ...       ...\n",
            "2995    -119.86     34.42       1450.0      1258.0  positive\n",
            "2996    -118.14     34.06       5257.0      3496.0  positive\n",
            "2997    -119.70     36.30        956.0       693.0   neutral\n",
            "2998    -117.12     34.10         96.0        46.0  negative\n",
            "2999    -119.63     34.42       1765.0       753.0   neutral\n",
            "\n",
            "[3000 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# from pandas.core.arrays.datetimes import DataFrame\n",
        "import pandas as pd\n",
        "from prompt_toolkit import output\n",
        "from re import X\n",
        "from textblob.en import positive\n",
        "# If you don't have an explicit 'sentiment' column, \n",
        "# identify which can be used as a proxy and create a 'sentiment' column based on\n",
        "# the proxy column. \n",
        "\n",
        "\n",
        "# Your code here:\n",
        "# Hint: use '.map' method\n",
        "def population(x):\n",
        "  if x > 1000:\n",
        "    output = 'positive'\n",
        "  elif 500<x<1000:\n",
        "    output = 'neutral'\n",
        "  else:\n",
        "    output = 'negative'\n",
        "  return output\n",
        "dataset['sentiment'] = dataset['population'].apply(population)\n",
        "    \n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Rvf68_vs7iJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "7919415e-221a-4856-86d9-3cd57dde0b4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    1798\n",
              "neutral      895\n",
              "negative     307\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Now let's take a look at the distribution of labels (i.e. sentiment values)\n",
        "# across the dataset.\n",
        "\n",
        "# Display a bar plot based on value counts of the 'sentiment' column [~ 1 line] \n",
        "\n",
        "# Your code here:\n",
        "dataset['sentiment'].value_counts().plot(kind='bar',figsize=(10,6),grid='-')\n",
        "dataset['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXNqb5Z5-T5e"
      },
      "source": [
        "**Answer this question in your report:**\n",
        "\n",
        "What problem we see with the dataset, if any?\n",
        "\n",
        "If there is a problem, how it can impact classification?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jTGhg3yC76Ai"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Let's create a separate numerical column 'label', \n",
        "# which will be used by our classifier.\n",
        "\n",
        "# Create a new column 'label' based on values in the 'sentiment' column.\n",
        "# It is up to you what number to assign to each category. [~ 1 line]\n",
        "# For example, if there are 3 categories (\"positive\", \"negative\", \"neutral\"),\n",
        "# I would use something like:\n",
        "# \n",
        "# >>> df[<your sentiment column>].map({\"positive\":2, \"negative\":1, \"neutral\":0})\n",
        "\n",
        "\n",
        "# Your code here:\n",
        "\n",
        "\n",
        "def sentiment(x):\n",
        "  if x == 'positive' :\n",
        "    output = 2\n",
        "  elif x == 'neutral' :\n",
        "    output = 0\n",
        "  else:\n",
        "    output = 1\n",
        "  return output\n",
        "  \n",
        "  dataset['label'] = dataset['sentiment'].apply(sentiment)\n",
        "\n",
        "  print(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "8M5j1qUY8fb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "2a4f239d-f576-41ed-cd02-be06c50c8c3c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-fef742b4a4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"positive\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"grey\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \"\"\"\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \"\"\"\n\u001b[1;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[1;32m    507\u001b[0m                 \u001b[0;31m# get size of resulting text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0mbox_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0;31m# find possible places using integral image:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[1] + self.margin,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageDraw.py\u001b[0m in \u001b[0;36mtextsize\u001b[0;34m(self, text, font, spacing, direction, features, language, stroke_width)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfont\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstroke_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     def multiline_textsize(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(self, text, *args, **kwargs)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morientation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROTATE_90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROTATE_270\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFont.py\u001b[0m in \u001b[0;36mgetsize\u001b[0;34m(self, text, direction, features, language, stroke_width)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \"\"\"\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         return (\n\u001b[1;32m    264\u001b[0m             \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstroke_width\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# To further get a notion of our dataset, let's display \n",
        "# a word cloud for each sentiment category, present in your dataset. [~ 7 lines per category]\n",
        "\n",
        "# You are free to use the following code as a general guide.\n",
        "\n",
        "# First let's extract only positive sentences\n",
        "# >>> positive = dataset[dataset[<sentiment column>] == \"positive\"]\n",
        "# Now let's write all positive entries into one variable\n",
        "# >>> text = \"\".join([i for i in positive[<sentence column>]])\n",
        "# The following creates a WordCloud instance\n",
        "# >>> wordcloud = WordCloud(background_color=\"grey\").generate(text)\n",
        "# Finally, let's display our word cloud\n",
        "# >>> plt.figure(figsize=(15,10))\n",
        "# >>> plt.imshow(wordcloud, interpolation='bilinear')\n",
        "# >>> plt.axis(\"off\")\n",
        "# >>> plt.show()\n",
        "\n",
        "# Your code here:\n",
        "positive = dataset[dataset['sentiment'] == \"positive\"]\n",
        "text = \"\".join([i for i in positive['sentiment']])\n",
        "wordcloud = WordCloud(background_color=\"grey\").generate(text)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-VlqPfI8BMI"
      },
      "outputs": [],
      "source": [
        "# For a more interactive exploration of your dataset, \n",
        "# we will use 'scattertext' library, imported as st\n",
        "\n",
        "# Adjust the following code to work with your dataset\n",
        "# Leave this line as is\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Now let's remove stopwords\n",
        "nltk.download('stopwords')\n",
        "stpwrds = stopwords.words('english')\n",
        "\n",
        "# Let's exclude neutral sentences, if there are any\n",
        "# Use the following example as a reference:\n",
        "# >>> ds = dataset[dataset[\"sentiment\"] != \"neutral\"].copy()\n",
        "\n",
        "# The following code puts your sentences into lower case and removes stopwords\n",
        "# Change '<Your Sentences Column>' to the name of the column with sentences.\n",
        "ds['<Your Sentences Column>'] = ds['<Your Sentences Column>'].apply(\n",
        "    lambda words: ' '.join(\n",
        "        str(word).lower() for word in words.split() \n",
        "        if str(word).lower() not in stpwrds)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN3tF4Eb9OWw"
      },
      "outputs": [],
      "source": [
        "# Let's create a corpus for the following plot.\n",
        "# It is possible, that this will take a long time, \n",
        "# when the whole ds is provided. In this case, pick a slice of your dataset,\n",
        "# i.e. ds[:1000], or ds[2000:3500], etc.\n",
        "corpus = st.CorpusFromPandas(ds,\n",
        "                             category_col= ... , # provide the name of your sentiment column here\n",
        "                             text_col= ... , # provide the name of your sentences' column here\n",
        "                             nlp=nlp\n",
        "                             ).build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWnqOJ3t9Pdy"
      },
      "outputs": [],
      "source": [
        "# The following code will create an interactive plot and save it as 'my_plot.html'.\n",
        "# Download it to your machine and open in a separate tab to explore.\n",
        "# Include a screenshot in your report. \n",
        "html = st.produce_scattertext_explorer(\n",
        "    corpus,\n",
        "    category=\"negative\",\n",
        "    not_category_name=\"positive\",\n",
        "    transform=st.Scalers.log_scale_standardize\n",
        ")\n",
        "open('./my_plot.html', 'wb').write(html.encode('utf-8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZMYGO0MAO_g"
      },
      "source": [
        "# Sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xy2pWGDCR_3"
      },
      "outputs": [],
      "source": [
        "# Let's preprocess dataset first\n",
        "# First, put your sentences in a lowercase [~ 1 line]\n",
        "# Suggestion: create a separate variable (e.g. corpus)\n",
        "# to store sentences from the dataset\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkbQNnd3GVqz"
      },
      "outputs": [],
      "source": [
        "# Now, let's replace hyperlinks, if any exist [~ 1line]\n",
        "# Hint: regex for hyperlinks is r\"http\\S+\"\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCBNBr5iGwjb"
      },
      "outputs": [],
      "source": [
        "# Finally, let's remove punctuations\n",
        "# Hint: regex for punctuations r\"[^A-Za-z0-9]+\"\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZklAk3QH8Sl"
      },
      "outputs": [],
      "source": [
        "# Now let's remove stopwords\n",
        "nltk.download('stopwords')\n",
        "stpwrds = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUvPx2u6IP9s"
      },
      "outputs": [],
      "source": [
        "# Remove stopwords from the text [~ 1 line]\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b7nzdoQI_76"
      },
      "outputs": [],
      "source": [
        "# Lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Create an instance of a WhitespaceTokenizer [1 line],\n",
        "# and WordNetLemmatizer [1 line]\n",
        "\n",
        "# Perform lemmatization on your sentences,\n",
        "# for example, if my sentence array is stored \n",
        "# in a corpus variable, I would use the following code:\n",
        "# >>> corpus = corpus.apply(\n",
        "# >>>    lambda words: ' '.join(\n",
        "# >>>        lemmatizer.lemmatize(word) for word in tokenizer.tokenize(words)\n",
        "# >>>        )\n",
        "# >>>    )\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7Dj2d36RNSr"
      },
      "outputs": [],
      "source": [
        "# Create an instance of a CountVectorizer [1 line]\n",
        "# and encode your sentences [~ 1 line]\n",
        "# hint: look into fit_transform\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJsONPEFR8bI"
      },
      "outputs": [],
      "source": [
        "# Create a separate variable, which holds a numpy array of labels [1 line]\n",
        "# Hint: use to_numpy()\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxIEjo2bR-Jh"
      },
      "outputs": [],
      "source": [
        "# Create a train and test dataset with 'train_test_split' [1 line]\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVvIJkWlSzN7"
      },
      "outputs": [],
      "source": [
        "# Create an instance of a MultinomialNB model [1 line]\n",
        "# and fit it with a training data [1 line]\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQWFVIrGTb5D"
      },
      "outputs": [],
      "source": [
        "# Evaluate your model on a test dataset [~ 1 line]\n",
        "# Hint: display the accuracy, achieved on a test data\n",
        "\n",
        "# Your code here \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77ls_QPlT1Pg"
      },
      "outputs": [],
      "source": [
        "# Create an instance of a ComplementNB model [1 line]\n",
        "# and fit it with a training data [1 line] \n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmoECEhNUtao"
      },
      "outputs": [],
      "source": [
        "# Evaluate your model on a test dataset [~ 1 line]\n",
        "# Hint: display the accuracy, achieved on a test data\n",
        "\n",
        "# Your code here \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjOAnlu6XTw4"
      },
      "outputs": [],
      "source": [
        "# For both models calculate precision, recall and F1 scores [~ 8 lines]\n",
        "\n",
        "# Your code here:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For both models display confusion matrix [~ 6 lines]\n",
        "# Hint: metrics.confusion_matrix can be used to calculate the matrix\n",
        "# and metrics.ConfusionMatrixDisplay can be used for plotting\n",
        "\n",
        "# Your code here:\n"
      ],
      "metadata": {
        "id": "YV6IHPpuR6JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report"
      ],
      "metadata": {
        "id": "dkLo9y3WYMI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hebTIzmiZp-"
      },
      "outputs": [],
      "source": [
        "# Finally, compose a report, which will include your thoughts on the data you've explored:\n",
        "# Include all plots, you've generated accompanied with your analysis.\n",
        "# Include analysis of 2 classifiers you've used in this analysis. Which of them was better and why?\n",
        "# Again, include calculated scores and plots, accompanied with your analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4irwZuolcip"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}